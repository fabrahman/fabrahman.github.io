<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Faeze Brahman</title> <meta name="author" content="Faeze Brahman"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://fabrahman.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">mentees</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Faeze</span> Brahman </h1> <p class="desc"><a href="#">Postdoctoral Researcher</a>. AI2|UW</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg?cfa0e08c5e74dd4965e002a9473e4508" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>Allen Institute for AI</p> <p>Seattle, WA</p> </div> </div> <div class="clearfix"> <p>I am a post-doctoral researcher at <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">Allen Institute for AI</a> and the <a href="https://www.cs.washington.edu/" rel="external nofollow noopener" target="_blank">Paul G. Allen School of Computer Science &amp; Engineering</a> at the <a href="https://www.cs.washington.edu/" rel="external nofollow noopener" target="_blank">University of Washington</a> working with <a href="https://homes.cs.washington.edu/~yejin/" rel="external nofollow noopener" target="_blank">Yejin Choi</a>. Prior to this, I did my Ph.D. (2022) in Computer Science at the University of California, Santa Cruz, working with <a href="https://sites.google.com/site/snigdhac/" rel="external nofollow noopener" target="_blank">Snigdha Chaturvedi</a>. I hold a master degree (2018) in Computer Science and a master (2014) and bachelor (2012) degree in Electrical Engineering. I have a broad set of research interests:</p> <ul> <li> <strong>Understanding language modelâ€™s capabilities and limitations</strong> in the wild under <strong>unseen or changing situations</strong> and <strong>developing efficient algorithms</strong> to address these limitations beyond just scaling. (This also includes better design for collaborative strategies and HCI interfaces to combine the best of Human and AI abilities.)</li> <li>Building <strong>Human-centered</strong> AI system that are more <strong>reliable and safe</strong> to use in various contexts by better <strong>alignment techniques</strong>.</li> <li>Developing robust and meaningful <strong>evaluation frameworks</strong> to investigate the <strong>emergent bahaviors of LLMs</strong> that are challenging to measure.</li> </ul> <p>Please feel free to get in touch if you want to chat, collaborate or brainstorm!</p> <p>Previously, I interned at Microsoft Research, working on controllable grounded text generation; and at AI2, working on unsupervised rationale generation for non-monotonic reasoning.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jan, 2025</th> <td> Our works on <a href="https://arxiv.org/abs/2407.18370" rel="external nofollow noopener" target="_blank">Reliable LLM-based evaluation with human agreement guarantee</a> and <a href="https://arxiv.org/abs/2406.04770" rel="external nofollow noopener" target="_blank">Benchmarking LLMs using real-world user queries</a> have been accepted to appear at ICLR 2025. </td> </tr> <tr> <th scope="row">Jan, 2025</th> <td> Our work on studying <a href="https://arxiv.org/abs/2409.09013" rel="external nofollow noopener" target="_blank">Utility-Truthfulness trade-off in LLM agents</a> has been accepted to appear at NAACL 2025. </td> </tr> <tr> <th scope="row">Dec, 2024</th> <td> I am attending NeurIPSâ€™24 in ğŸVancouver to present <a href="https://arxiv.org/pdf/2406.18510" rel="external nofollow noopener" target="_blank">WildTeaming</a> (@ main), <a href="https://arxiv.org/abs/2407.12043" rel="external nofollow noopener" target="_blank">CoCoNoT</a> (@ D&amp;B Track), <a href="https://arxiv.org/abs/2409.16427" rel="external nofollow noopener" target="_blank">HAICOSYSTEM</a> and <a href="https://openreview.net/pdf?id=ejgREMlnLa" rel="external nofollow noopener" target="_blank">AI-LieDar</a> (@ Safety &amp; Trusthworthy Agents workshop). Come say ğŸ‘‹ğŸ¼! </td> </tr> <tr> <th scope="row">Nov, 2024</th> <td> We released <a href="https://arxiv.org/abs/2411.15124" rel="external nofollow noopener" target="_blank">TÃ¼lu 3</a>: a family of post-trained models with every step in the pipeline open </td> </tr> <tr> <th scope="row">Oct, 2024</th> <td> New papers on <a href="https://arxiv.org/abs/2409.16427" rel="external nofollow noopener" target="_blank">multi-turn safety evaluation, HAICOSYSTEM</a> and <a href="https://arxiv.org/abs/2410.19133" rel="external nofollow noopener" target="_blank">preference annotation, HybridPref</a>! </td> </tr> <tr> <th scope="row">Oct, 2024</th> <td> selected as a Rising Star to attend the GenAI Workshop at UMass Amherst! </td> </tr> <tr> <th scope="row">Sep, 2024</th> <td> Serving as Area Chair for <a href="https://coling2025.org/committees/organization/" rel="external nofollow noopener" target="_blank">COLING 2025</a>. </td> </tr> <tr> <th scope="row">Sep, 2024</th> <td> <a href="https://arxiv.org/pdf/2406.18510" rel="external nofollow noopener" target="_blank">WildTeaming</a> and <a href="https://arxiv.org/abs/2407.12043" rel="external nofollow noopener" target="_blank">CoCoNoT</a> are now accepted at NeurIPS 2024! </td> </tr> <tr> <th scope="row">Aug, 2024</th> <td> Supper excited about our recent work on <a href="https://arxiv.org/abs/2407.18370" rel="external nofollow noopener" target="_blank">Cascaded Selective Evaluation</a>! </td> </tr> <tr> <th scope="row">Jul, 2024</th> <td> New paper on <a href="https://arxiv.org/abs/2407.12043" rel="external nofollow noopener" target="_blank">Contextual Noncompliance</a> ğŸ¥¥! </td> </tr> <tr> <th scope="row">Jul, 2024</th> <td> New papers on <a href="https://arxiv.org/pdf/2406.18510" rel="external nofollow noopener" target="_blank">WildTeaming at Scale</a> and <a href="https://arxiv.org/pdf/2406.04770" rel="external nofollow noopener" target="_blank">WildBench</a> ğŸ¦! </td> </tr> <tr> <th scope="row">May, 2024</th> <td> I will be attending ICLRâ€™24 in ğŸ‡¦ğŸ‡¹ Vienna to present 3 papers! Check them out <a href="https://fabrahman.github.io/publications/">here</a> </td> </tr> <tr> <th scope="row">May, 2024</th> <td> Invited talk at Bocconi University on Creativity and Constrained Problem Solving! <a href="https://drive.google.com/file/d/1Hnlfz-JMFE0o0ISYL3PvFElG0gVVBEkl/view?usp=sharing" rel="external nofollow noopener" target="_blank">slides</a> </td> </tr> <tr> <th scope="row">Apr, 2024</th> <td> <a href="https://aclanthology.org/2024.naacl-long.297.pdf" rel="external nofollow noopener" target="_blank">Macgyver</a> led by my intern Yufei Tian was accepted at NAACL 2024. </td> </tr> <tr> <th scope="row">Apr, 2024</th> <td> Invited talk at UBC NLP Group on Creativity and Constrained Problem Solving! <a href="https://drive.google.com/file/d/1Hnlfz-JMFE0o0ISYL3PvFElG0gVVBEkl/view?usp=sharing" rel="external nofollow noopener" target="_blank">slides</a> </td> </tr> <tr> <th scope="row">Oct, 2023</th> <td> Iâ€™m honored to serve as a Senior Area Chair for <a href="https://2024.naacl.org/" rel="external nofollow noopener" target="_blank">NAACL 2024</a>! </td> </tr> <tr> <th scope="row">Oct, 2023</th> <td> Our workshop on Narrative Understanding is accepted to EMNLP 2024! </td> </tr> <tr> <th scope="row">May, 2023</th> <td> <a href="https://aclanthology.org/2023.acl-long.112.pdf" rel="external nofollow noopener" target="_blank">REV</a>, led by our intern Hanjie Chen is accepted at ACL 2023! </td> </tr> <tr> <th scope="row">Mar, 2023</th> <td> Talk at UMass NLP seminars! </td> </tr> <tr> <th scope="row">Feb, 2023</th> <td> Guest lectures at the University of Washington (CSE 599)! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">ICLR</a></abbr></div> <div id="jung2024trustescalatellmjudges" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2407.18370" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement</a></div> <div class="author"> Jaehun Jung,Â <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman</span>,Â andÂ Yejin Choi</div> <div class="periodical"> <em>In To appear at ICLR</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/jaehunjung1/cascaded-selective-evaluation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jung2024trustescalatellmjudges</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jung, Jaehun and Brahman, Faeze and Choi, Yejin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.18370}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.18370}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{To appear at ICLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">NeurIPS</a></abbr></div> <div id="brahman2024artsayingnocontextual" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2407.12043" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">The Art of Saying No: Contextual Noncompliance in Language Models</a></div> <div class="author"> <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman*</span>,Â Sachin Kumar*,Â Vidhisha Balachandran,Â Pradeep Dasigi,Â Valentina Pyatkin,Â Abhilasha Ravichander,Â Sarah Wiegreffe,Â Nouha Dziri,Â Khyathi Chandu,Â Jack Hessel,Â Yulia Tsvetkov,Â Noah A. Smith,Â Yejin Choi,Â andÂ Hannaneh Hajishirzi</div> <div class="periodical"> <em>In Neural Information Processing Systems (NeurIPS) - Dataset and Benchmark Track</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://allenai.org/blog/broadening-the-scope-of-noncompliance-when-and-how-ai-models-should-not-comply-with-user-requests-18b028c5b538" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/allenai/noncompliance" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huggingface.co/datasets/allenai/coconot" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">brahman2024artsayingnocontextual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Art of Saying No: Contextual Noncompliance in Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brahman*, Faeze and Kumar*, Sachin and Balachandran, Vidhisha and Dasigi, Pradeep and Pyatkin, Valentina and Ravichander, Abhilasha and Wiegreffe, Sarah and Dziri, Nouha and Chandu, Khyathi and Hessel, Jack and Tsvetkov, Yulia and Smith, Noah A. and Choi, Yejin and Hajishirzi, Hannaneh}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2407.12043}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.12043}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing Systems (NeurIPS) - Dataset and Benchmark Track}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://huggingface.co/datasets/allenai/coconot}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">preprint</abbr></div> <div id="zhou2024haicosystemecosystemsandboxingsafety" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2409.16427" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">HAICOSYSTEM: An Ecosystem for Sandboxing Safety Riswks in Human-AI Interactions</a></div> <div class="author"> Xuhui Zhou,Â <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman*</span>,Â Hyunwoo Kim*,Â Liwei Jiang,Â Hao Zhu,Â Ximing Lu,Â Frank Xu,Â Bill Yuchen Lin,Â Yejin Choi,Â Niloofar Mireshghallah,Â Ronan Le Bras,Â andÂ Maarten Sap</div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/XuhuiZhou/HAI-Cosys" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://haicosystem.streamlit.app" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">zhou2024haicosystemecosystemsandboxingsafety</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HAICOSYSTEM: An Ecosystem for Sandboxing Safety Riswks in Human-AI Interactions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Xuhui and Brahman*, Faeze and Kim*, Hyunwoo and Jiang, Liwei and Zhu, Hao and Lu, Ximing and Xu, Frank and Lin, Bill Yuchen and Choi, Yejin and Mireshghallah, Niloofar and Bras, Ronan Le and Sap, Maarten}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2409.16427}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.AI}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2409.16427}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">NAACL</a></abbr></div> <div id="tian2023macgyver" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2311.09682" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">MacGyver: Are Large Language Models Creative Problem Solvers?</a></div> <div class="author"> Yufei Tian,Â Abhilasha Ravichander,Â Lianhui Qin,Â Ronan Le Bras,Â Raja Marjieh,Â Nanyun Peng,Â Yejin Choi,Â Thomas L. Griffiths,Â andÂ <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman</span> </div> <div class="periodical"> <em>In Proceedings of NAACL</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/allenai/MacGyver" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <span style="color: red; font-weight: bold; ; border: 1px solid red; background-color: transparent;">ğŸ† Best Paper Nomination</span> </div> <div class="abstract hidden"> <p>We explore the creative problem-solving capabilities of modern large language models (LLMs) in a constrained setting. The setting requires circumventing a cognitive bias known in psychology as â€functional fixednessâ€ to use familiar objects in innovative or unconventional ways. To this end, we create MacGyver, an automatically generated dataset consisting of 1,600 real-world problems that deliberately trigger functional fixedness and require thinking â€™out-of-the-boxâ€™. We then present our collection of problems to both LLMs and humans to compare and contrast their problem-solving abilities. We show that MacGyver is challenging for both groups, but in unique and complementary ways. For example, humans typically excel in solving problems that they are familiar with but may struggle with tasks requiring domain-specific knowledge, leading to a higher variance. On the other hand, LLMs, being exposed to a variety of highly specialized knowledge, attempt broader problems but are prone to overconfidence and propose actions that are physically infeasible or inefficient. We also provide a detailed error analysis of LLMs, and demonstrate the potential of enhancing their problem-solving ability with novel prompting techniques such as iterative step-wise reflection and divergent-convergent thinking. This work provides insight into the creative problem-solving capabilities of humans and AI and illustrates how psychological paradigms can be extended into large-scale tasks for comparing humans and machines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tian2023macgyver</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MacGyver: Are Large Language Models Creative Problem Solvers?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tian, Yufei and Ravichander, Abhilasha and Qin, Lianhui and Bras, Ronan Le and Marjieh, Raja and Peng, Nanyun and Choi, Yejin and Griffiths, Thomas L. and Brahman, Faeze}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of NAACL}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2311.09682}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2311.09682}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">nomination</span> <span class="p">=</span> <span class="s">{ğŸ† Best Paper Nomination}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">ICLR</a></abbr></div> <div id="west2023generative" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2311.00059" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">The Generative AI Paradox: "What It Can Create, It May Not Understand"</a></div> <div class="author"> <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman*</span>,Â Peter West*,Â Ximing Lu*,Â Nouha Dziri*,Â Linjie Li*,Â Jena D. Hwang,Â Liwei Jiang,Â Jillian Fisher,Â Abhilasha Ravichander,Â Khyathi Chandu,Â Benjamin Newman,Â Pang Wei Koh,Â Allyson Ettinger,Â andÂ Yejin Choi</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>The recent wave of generative AI has sparked unprecedented global attention, with both excitement and concern over potentially superhuman levels of artificial intelligence: models now take only seconds to produce outputs that would challenge or exceed the capabilities even of expert humans. At the same time, models still show basic errors in understanding that would not be expected even in non-expert humans. This presents us with an apparent paradox: how do we reconcile seemingly superhuman capabilities with the persistence of errors that few humans would make? In this work, we posit that this tension reflects a divergence in the configuration of intelligence in todayâ€™s generative models relative to intelligence in humans. Specifically, we propose and test the Generative AI Paradox hypothesis: generative models, having been trained directly to reproduce expert-like outputs, acquire generative capabilities that are not contingent upon â€“ and can therefore exceed â€“ their ability to understand those same types of outputs. This contrasts with humans, for whom basic understanding almost always precedes the ability to generate expert-level outputs. We test this hypothesis through controlled experiments analyzing generation vs. understanding in generative models, across both language and image modalities. Our results show that although models can outperform humans in generation, they consistently fall short of human capabilities in measures of understanding, as well as weaker correlation between generation and understanding performance, and more brittleness to adversarial inputs. Our findings support the hypothesis that modelsâ€™ generative capability may not be contingent upon understanding capability, and call for caution in interpreting artificial intelligence by analogy to human intelligence</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">west2023generative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Generative AI Paradox: "What It Can Create, It May Not Understand"}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brahman*, Faeze and West*, Peter and Lu*, Ximing and Dziri*, Nouha and Li*, Linjie and Hwang, Jena D. and Jiang, Liwei and Fisher, Jillian and Ravichander, Abhilasha and Chandu, Khyathi and Newman, Benjamin and Koh, Pang Wei and Ettinger, Allyson and Choi, Yejin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2311.00059}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2311.00059}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.AI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">ICLR</a></abbr></div> <div id="Brahman2023PlaSma" class="col-sm-8"> <div class="title"><a href="https://arxiv.org/abs/2305.19472" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning</a></div> <div class="author"> <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman</span>,Â Chandra Bhagavatula,Â Valentina Pyatkin*,Â Jena D. Hwang*,Â Xiang Lorraine Li,Â Hirona J. Arai,Â Soumya Sanyal,Â Keisuke Sakaguchi,Â Xiang Ren,Â andÂ Yejin Choi</div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/allenai/PlaSma" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines. It involves integrating common-sense knowledge to reason about complex contextualized situations that are often counterfactual, e.g. â€™scheduling a doctorâ€™s appointment without a phoneâ€™. While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues. In this paper, we advocate planning using smaller language models. We present PlaSma, a novel two-pronged approach to endow small language models with procedural knowledge and (counterfactual) planning capabilities. More concretely, we develop symbolic procedural knowledge distillation to enhance the implicit knowledge in small language models and an inference-time algorithm to facilitate more structured and accurate reasoning. In addition, we introduce a novel task, Counterfactual Planning, that requires a revision of a plan to cope with a counterfactual situation. In both the original and counterfactual setting, we show that orders-of-magnitude smaller models (770M-11B parameters) can compete and often surpass their larger teacher modelsâ€™ capabilities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Brahman2023PlaSma</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brahman, Faeze and Bhagavatula, Chandra and Pyatkin*, Valentina and Hwang*, Jena D. and Li, Xiang Lorraine and Arai, Hirona J. and Sanyal, Soumya and Sakaguchi, Keisuke and Ren, Xiang and Choi, Yejin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ArXiv preprint}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2305.19472}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">EMNLP</a></abbr></div> <div id="lu2023inference" class="col-sm-8"> <div class="title"><a href="https://aclanthology.org/2023.emnlp-main.424" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning</a></div> <div class="author"> Ximing Lu,Â <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman</span>,Â Peter West,Â Jaehun Jang,Â Khyathi Chandu,Â Abhilasha Ravichander,Â Lianhui Qin,Â Prithviraj Ammanabrolu,Â Liwei Jiang,Â Sahana Ramnath,Â andÂ  others</div> <div class="periodical"> <em>In Proceedings of EMNLP</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/GXimingLu/IPA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2023inference</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Ximing and Brahman, Faeze and West, Peter and Jang, Jaehun and Chandu, Khyathi and Ravichander, Abhilasha and Qin, Lianhui and Ammanabrolu, Prithviraj and Jiang, Liwei and Ramnath, Sahana and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of EMNLP}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.emnlp-main.424}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">ICLR</a></abbr></div> <div id="welleck2023generating" class="col-sm-8"> <div class="title"><a href="https://openreview.net/forum?id=hH36JeQZDaO" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">Generating Sequences by Learning to Self-Correct</a></div> <div class="author"> Sean Welleck*,Â Ximing Lu*,Â Peter West+,Â Faeze Brahman +,Â Tianxiao Shen,Â Daniel Khashabi,Â andÂ Yejin Choi</div> <div class="periodical"> <em>In The Eleventh International Conference on Learning Representations </em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Sequence generation applications require satisfying semantic constraints, such as ensuring that programs are correct, using certain keywords, or avoiding undesirable content. Language models, whether fine-tuned or prompted with few-shot demonstrations, frequently violate these constraints, and lack a mechanism to iteratively revise their outputs. Moreover, some powerful language models are of extreme scale or inaccessible, making it inefficient, if not infeasible, to update their parameters for task-specific adaptation. We present Self-Correction, an approach that decouples an imperfect base generator (an off-the-shelf language model or supervised sequence-to-sequence model) from a separate corrector that learns to iteratively correct imperfect generations. To train the corrector, we propose an online training procedure that can use either scalar or natural language feedback on intermediate imperfect generations. We show that Self-Correction improves upon the base generator in three diverse generation tasks - mathematical program synthesis, lexically-constrained generation, and toxicity control - even when the corrector is much smaller than the base generator. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">welleck2023generating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generating Sequences by Learning to Self-Correct}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Welleck*, Sean and Lu*, Ximing and West+, Peter and +, {Faeze Brahman} and Shen, Tianxiao and Khashabi, Daniel and Choi, Yejin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Eleventh International Conference on Learning Representations }</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=hH36JeQZDaO}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#c869bf"><a href="">EMNLP</a></abbr></div> <div id="jung-etal-2022-maieutic" class="col-sm-8"> <div class="title"><a href="https://aclanthology.org/2022.emnlp-main.82" target="_blank" style="color: rgb(0, 0, 0);font: size 14px; font-weight: 400;" rel="external nofollow noopener">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</a></div> <div class="author"> Jaehun Jung,Â Lianhui Qin,Â Sean Welleck,Â <span style="color: rgb(150, 87, 182);font-weight:400">Faeze Brahman</span>,Â Chandra Bhagavatula,Â Ronan Le Bras,Â andÂ Yejin Choi</div> <div class="periodical"> <em>In Proceedings of EMNLP</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/jaehunjung1/Maieutic-Prompting" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jung-etal-2022-maieutic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jung, Jaehun and Qin, Lianhui and Welleck, Sean and Brahman, Faeze and Bhagavatula, Chandra and Le Bras, Ronan and Choi, Yejin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of EMNLP}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Abu Dhabi, United Arab Emirates}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.emnlp-main.82}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2022.emnlp-main.82}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1266--1279}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%66%61%65.%62%72%61%68%6D%61%6E@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=viCG2ikAAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/fabrahman" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/faeze_brh" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> Please conatct me at fae.brahman@gmail.com </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Faeze Brahman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 04, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>